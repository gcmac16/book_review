## Moderation, Inc.

- Section 230 has rightly earned reputation as super first amendment providing protections to sites' not afforded anywhere else in the world
- In general platforms have been notoriously tigh-lipped about content removal practices; changed in 2017/2018 as they came under fire for allowing illegal user content
- Pinterest worked w/ National Eating Disorder Association to compile a list of keywords to make sure they didn't show images that might contribute to eating disorders to those that would be most susceptible to them
    - Apprach to sensitive issue not required by law
    - product of socially responsible platform unrestrained by legal requirements that developed a creative solution
- Human reviewers remain essential to removing content and training ML algorithms because human judgment is critical to making contextualized decisions on content - YouTube Chief Susan Wojcicki
- Estimated that ML increased amount of video removals on YouTube by 5x
    - removed 70% of content that's "violent extremism" within 8 hours
- Federal Law requires platforms to report child porn to National Center for Missing and Exploited Children only if they have "actual knowledge" of user's apparent violation
    - Don't have obligation to actively monitor but services still do
- Online platforms often reacto to criticism after their failure to moderate has cause substantial harm
    - understament of the century
- Increased moderation not necessarily in line w/ security interests
    - If ISIS is using public forum to communicate, provide window into operation for law enforacment
- S230 reflects implicit contract between congress and tech companies: if platforms develop responsible and resaonable moderation policies, congress will grant them extraordinary legal immunity
    - For S230 to survive future challenges, must improve moderation practices and publicly explain how they've done so
